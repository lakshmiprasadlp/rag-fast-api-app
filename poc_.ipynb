{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPlOUw65k4iOAc8QUmnA9tK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":12,"metadata":{"id":"8Jl-XSuNUmS5","executionInfo":{"status":"ok","timestamp":1768382851017,"user_tz":-330,"elapsed":5465,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"outputs":[],"source":["%%capture\n","!pip install -q langchain langchain-community faiss-cpu  pypdf langchain-text-splitters\n"]},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","\n","\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n"],"metadata":{"id":"clc-EqEiVbML","executionInfo":{"status":"ok","timestamp":1768382852689,"user_tz":-330,"elapsed":1679,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"e53APbKYV-xs","executionInfo":{"status":"ok","timestamp":1768382854906,"user_tz":-330,"elapsed":397,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","\n","uploaded = files.upload()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"Fhl6EavhWB-G","outputId":"2054906a-3cbc-4a24-f04f-f7ebe66e4d7a","executionInfo":{"status":"ok","timestamp":1768382958667,"user_tz":-330,"elapsed":103188,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-42a56056-5065-4892-8ca6-1c8eba27b41d\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-42a56056-5065-4892-8ca6-1c8eba27b41d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving yolo.pdf to yolo.pdf\n"]}]},{"cell_type":"code","source":["from langchain_community.document_loaders import PyPDFLoader, TextLoader\n","\n","file_name = list(uploaded.keys())[0]\n","\n","if file_name.endswith(\".pdf\"):\n","    loader = PyPDFLoader(file_name)\n","else:\n","    loader = TextLoader(file_name)\n","\n","documents = loader.load()"],"metadata":{"id":"OJT2oueGWHdH","executionInfo":{"status":"ok","timestamp":1768382978285,"user_tz":-330,"elapsed":19622,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["from langchain_text_splitters import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=500,\n","    chunk_overlap=100\n",")\n","\n","chunks = text_splitter.split_documents(documents)\n","\n","len(chunks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZUGX0sByWuqa","executionInfo":{"status":"ok","timestamp":1768382984775,"user_tz":-330,"elapsed":369,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}},"outputId":"9262ab95-ca52-4b19-af98-835624a1142a"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["106"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["from langchain_openai import OpenAIEmbeddings\n","\n","embeddings = OpenAIEmbeddings(\n","    model=\"text-embedding-3-small\",\n",")"],"metadata":{"id":"FC2EJocpW94r","executionInfo":{"status":"ok","timestamp":1768382991333,"user_tz":-330,"elapsed":634,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["#gpt-4.1-nano"],"metadata":{"id":"Iktsa_39ztG3","executionInfo":{"status":"ok","timestamp":1768382996949,"user_tz":-330,"elapsed":363,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["!pip install -qU langchain-community faiss-cpu"],"metadata":{"id":"tbG5zwUrYcgh","executionInfo":{"status":"ok","timestamp":1768383002256,"user_tz":-330,"elapsed":4829,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["from langchain_community.vectorstores import FAISS\n","\n","vectorstore = FAISS.from_documents(chunks, embeddings)\n"],"metadata":{"id":"1If4oYoNXoCL","executionInfo":{"status":"ok","timestamp":1768383005142,"user_tz":-330,"elapsed":2890,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["#vectorstore.index_to_docstore_id"],"metadata":{"id":"PwP7nrNScThr","executionInfo":{"status":"ok","timestamp":1768383005142,"user_tz":-330,"elapsed":3,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"],"metadata":{"id":"DpJGBO1CcTM0","executionInfo":{"status":"ok","timestamp":1768383006319,"user_tz":-330,"elapsed":2,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["retriever.invoke('who is the pm of india')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KNdVuJSvcp4j","executionInfo":{"status":"ok","timestamp":1768383008971,"user_tz":-330,"elapsed":942,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}},"outputId":"141f2845-5769-43cc-b919-b6b6e80e68da"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(id='81d2977c-088d-42ea-9cdc-65e6224a7198', metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-11T00:04:54+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-11T00:04:54+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'yolo.pdf', 'total_pages': 10, 'page': 3, 'page_label': '4'}, page_content='classify regions, predict bounding boxes for high scoring\\nregions, etc. Our system replaces all of these disparate parts\\nwith a single convolutional neural network. The network\\nperforms feature extraction, bounding box prediction, non-\\nmaximal suppression, and contextual reasoning all concur-\\nrently. Instead of static features, the network trains the fea-\\ntures in-line and optimizes them for the detection task. Our\\nuniﬁed architecture leads to a faster, more accurate model\\nthan DPM.'),\n"," Document(id='5393492e-5e4c-44e4-881f-1f2b03c9898a', metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-11T00:04:54+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-11T00:04:54+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'yolo.pdf', 'total_pages': 10, 'page': 8, 'page_label': '9'}, page_content='detection networks on convolutional feature maps. CoRR,\\nabs/1504.06066, 2015. 3, 7\\n[30] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh,\\nS. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein,\\nA. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual\\nRecognition Challenge. International Journal of Computer\\nVision (IJCV), 2015. 3\\n[31] M. A. Sadeghi and D. Forsyth. 30hz object detection with\\ndpm v5. In Computer Vision–ECCV 2014 , pages 65–79.\\nSpringer, 2014. 5, 6'),\n"," Document(id='d952232d-6b4b-4e3e-bfe1-840250e15075', metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-11T00:04:54+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-11T00:04:54+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'yolo.pdf', 'total_pages': 10, 'page': 4, 'page_label': '5'}, page_content='63.4% while still maintaining real-time performance.\\nWe also train YOLO using VGG-16. This model is more\\naccurate but also signiﬁcantly slower than YOLO. It is use-\\nful for comparison to other detection systems that rely on\\nVGG-16 but since it is slower than real-time the rest of the\\npaper focuses on our faster models.\\nFastest DPM effectively speeds up DPM without sacri-\\nﬁcing much mAP but it still misses real-time performance\\nby a factor of 2 [38]. It also is limited by DPM’s relatively'),\n"," Document(id='a740bb31-1ba8-4a82-b136-0d40b6c40651', metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-11T00:04:54+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-11T00:04:54+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'yolo.pdf', 'total_pages': 10, 'page': 8, 'page_label': '9'}, page_content='dpm v5. In Computer Vision–ECCV 2014 , pages 65–79.\\nSpringer, 2014. 5, 6\\n[32] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus,\\nand Y . LeCun. Overfeat: Integrated recognition, localiza-\\ntion and detection using convolutional networks. CoRR,\\nabs/1312.6229, 2013. 4, 5')]"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["%%capture\n","!pip install -U langchain-openai"],"metadata":{"id":"L21H8gpc0aWQ","executionInfo":{"status":"ok","timestamp":1768383022840,"user_tz":-330,"elapsed":10302,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI(\n","    model=\"gpt-5-nano\")"],"metadata":{"id":"glCUqDAJYS_O","executionInfo":{"status":"ok","timestamp":1768383022841,"user_tz":-330,"elapsed":5,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import PromptTemplate"],"metadata":{"id":"jroICKIGdBqD","executionInfo":{"status":"ok","timestamp":1768383042630,"user_tz":-330,"elapsed":736,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["prompt = PromptTemplate(\n","    template=\"\"\"\n","      You are a helpful assistant.\n","      Answer ONLY from the provided transcript context.\n","      If the context is insufficient, just say you don't know.\n","\n","      {context}\n","      Question: {question}\n","    \"\"\",\n","    input_variables = ['context', 'question']\n",")"],"metadata":{"id":"EMeGHUzyc8DO","executionInfo":{"status":"ok","timestamp":1768383043335,"user_tz":-330,"elapsed":3,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n","context_text"],"metadata":{"id":"kpBib47bdUs0","executionInfo":{"status":"ok","timestamp":1768383056615,"user_tz":-330,"elapsed":800,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}},"colab":{"base_uri":"https://localhost:8080/","height":157},"outputId":"36461923-7ea2-48c8-aaba-6116702b638b"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'First, YOLO is extremely fast. Since we frame detection\\nas a regression problem we don’t need a complex pipeline.\\nWe simply run our neural network on a new image at test\\ntime to predict detections. Our base network runs at 45\\nframes per second with no batch processing on a Titan X\\nGPU and a fast version runs at more than 150 fps. This\\nmeans we can process streaming video in real-time with\\nless than 25 milliseconds of latency. Furthermore, YOLO\\n\\nONR N00014-13-1-0720, NSF IIS-1338054, and The Allen\\nDistinguished Investigator Award.\\n\\nVOC 2012 test mAP aero bike bird boat bottle bus car cat chair cow table dog horse mbike personplant sheep sofa train tv\\nMR CNN MORE DATA [11] 73.9 85.5 82.9 76.6 57.8 62.7 79.4 77.2 86.6 55.0 79.1 62.2 87.0 83.4 84.7 78.9 45.3 73.4 65.8 80.3 74.0\\nHyperNet VGG 71.4 84.2 78.5 73.6 55.6 53.7 78.7 79.8 87.7 49.6 74.9 52.1 86.0 81.7 83.3 81.8 48.6 73.5 59.4 79.9 65.7\\nHyperNet SP 71.3 84.1 78.3 73.3 55.5 53.6 78.6 79.6 87.5 49.5 74.9 52.1 85.6 81.6 83.2 81.6 48.4 73.2 59.3 79.7 65.6\\n\\nYou Only Look Once:\\nUniﬁed, Real-Time Object Detection\\nJoseph Redmon∗, Santosh Divvala∗†, Ross Girshick¶, Ali Farhadi∗†\\nUniversity of Washington∗, Allen Institute for AI†, Facebook AI Research¶\\nhttp://pjreddie.com/yolo/\\nAbstract\\nWe present YOLO, a new approach to object detection.\\nPrior work on object detection repurposes classiﬁers to per-\\nform detection. Instead, we frame object detection as a re-\\ngression problem to spatially separated bounding boxes and'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":[],"metadata":{"id":"qGFhmI37dmEX","executionInfo":{"status":"ok","timestamp":1768383060307,"user_tz":-330,"elapsed":742,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})"],"metadata":{"id":"DIMKCnkyZPbV","executionInfo":{"status":"ok","timestamp":1768383063014,"user_tz":-330,"elapsed":369,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["answer = llm.invoke(final_prompt)\n","print(answer.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_9VOq-jUdMe7","executionInfo":{"status":"ok","timestamp":1768383071332,"user_tz":-330,"elapsed":5932,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}},"outputId":"6ae02f63-8e07-4125-9fff-caa204743b28"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["No. The transcript discusses You Only Look Once (YOLO), a real-time object detection system, its speed (base network around 45 fps, fast version over 150 fps), predicting detections via regression, and real-time video latency under 25 ms, along with related references. Nuclear fusion is not mentioned.\n"]}]},{"cell_type":"code","source":["def ask_q(question):\n","  retrieved_docs    = retriever.invoke(question)\n","  final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})\n","  answer = llm.invoke(final_prompt)\n","  print(answer.content)"],"metadata":{"id":"uPEdBe_sdtqK","executionInfo":{"status":"ok","timestamp":1768383082061,"user_tz":-330,"elapsed":377,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["ask_q(\"explain yolo\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WLrqL1-NeLbr","executionInfo":{"status":"ok","timestamp":1768383098445,"user_tz":-330,"elapsed":14885,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}},"outputId":"89cffcd8-2418-4ede-ae22-5c0eafb70d40"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["YOLO stands for You Only Look Once. It’s a unified, real-time approach to object detection. Rather than using classifiers to perform detection, YOLO frames object detection as a regression problem to predict spatially separated bounding boxes (in a single pass). At test time, you simply run a single neural network on a new image to predict detections, without a complex pipeline. It’s extremely fast: the base network runs at about 45 frames per second on a Titan X (no batch processing), and a fast version runs at over 150 fps, enabling real-time streaming video with latency under ~25 ms.\n"]}]},{"cell_type":"code","source":["ask_q(\"who is the pm of india\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2O3FrebWePdp","executionInfo":{"status":"ok","timestamp":1768383103650,"user_tz":-330,"elapsed":5208,"user":{"displayName":"Lp Agboy","userId":"12653464857873971905"}},"outputId":"eab3ad3e-5fd0-487d-9e0d-39b35428f94a"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["I don't know.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Q5Br01nEebaq"},"execution_count":null,"outputs":[]}]}